{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive, userdata\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "github_token = userdata.get('github_token')\n",
    "github_username = userdata.get('github_username')\n",
    "try:\n",
    "  wandb_key = userdata.get('wandb_key')\n",
    "except userdata.SecretNotFoundError: \n",
    " wandb_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://$github_username:$github_token@github.com/developer-sidani/CharBERT.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r CharBERT/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /content/CharBERT/run_lm_finetuning.py \\\n",
    "    --model_type bert \\\n",
    "    --model_name_or_path bert-base-cased \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --wandb_key $wandb_key \\\n",
    "    --wandb_project CharBERT \\\n",
    "    --wandb_run_name \"bert_base_cased_wiki_eng\" \\\n",
    "    --train_data_file \"/content/drive/MyDrive/NLP/data/wiki-eng/train.txt\" \\\n",
    "    --eval_data_file  \"/content/drive/MyDrive/NLP/data/wiki-eng/eval.txt\" \\\n",
    "    --term_vocab \"/content/CharBERT/data/dict/term_vocab\" \\\n",
    "    --learning_rate 3e-5 \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --char_vocab \"/content/CharBERT/data/dict/bert_char_vocab\" \\\n",
    "    --mlm_probability 0.10 \\\n",
    "    --input_nraws 1000 \\\n",
    "    --per_gpu_train_batch_size 4 \\\n",
    "    --per_gpu_eval_batch_size 4 \\\n",
    "    --save_steps 10000 \\\n",
    "    --block_size 384 \\\n",
    "    --mlm \\\n",
    "    --overwrite_output_dir \\\n",
    "    --output_dir  \"/content/drive/MyDrive/NLP/output/wiki-eng/bert_base_cased_wiki_eng\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR='/content/drive/MyDrive/NLP/data/CoNLL2003'\n",
    "MODEL_DIR='/content/drive/MyDrive/NLP/output/wiki-eng/bert_base_cased_wiki_eng'\n",
    "OUTPUT_DIR='/content/drive/MyDrive/NLP/output/conll2003_ner'\n",
    "!python3 run_ner.py --data_dir ${DATA_DIR} \\\n",
    "                --model_type bert \\\n",
    "                --wandb_key $wandb_key \\\n",
    "                --wandb_project CharBERT \\\n",
    "                --wandb_run_name \"ner_conll2003\" \\\n",
    "                --model_name_or_path $MODEL_DIR \\\n",
    "                --output_dir ${OUTPUT_DIR} \\\n",
    "                --num_train_epochs 3 \\\n",
    "                --learning_rate 3e-5 \\\n",
    "                --char_vocab /content/CharBERT/data/dict/bert_char_vocab \\\n",
    "                --per_gpu_train_batch_size 6 \\\n",
    "                --do_train \\\n",
    "                --do_predict \\\n",
    "                --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual Extension Bert cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./CharBERT/run_lm_finetuning.py \\\n",
    "    --model_type bert \\\n",
    "    --model_name_or_path bert-base-multilingual-cased \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --train_data_file \"/content/drive/MyDrive/NLP/data/wiki/wikil_eng_wiki_ita_train.txt\" \\\n",
    "    --eval_data_file  \"/content/drive/MyDrive/NLP/data/wiki/wikil_eng_wiki_ita_val.txt\" \\\n",
    "    --term_vocab \"./CharBERT/data/dict/term_vocab\" \\\n",
    "    --learning_rate 3e-5 \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --char_vocab \"/content/CharBERT/data/dict/bert_char_vocab\" \\\n",
    "    --mlm_probability 0.10 \\\n",
    "    --wandb_key $wandb_key \\\n",
    "    --wandb_project CharBERT \\\n",
    "    --input_nraws 1000 \\\n",
    "    --per_gpu_train_batch_size 4 \\\n",
    "    --per_gpu_eval_batch_size 4 \\\n",
    "    --save_steps 10000 \\\n",
    "    --block_size 384 \\\n",
    "    --mlm \\\n",
    "    --overwrite_output_dir \\\n",
    "    --output_dir  \"/content/drive/MyDrive/NLP/output/multilingual/MLM_cased/wikil_eng_wiki_ita\" \\\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ner Multilingual CoNLL2003 ENGLISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./CharBERT/run_ner.py \\\n",
    "                    --data_dir \"/content/drive/MyDrive/NLP/data/CoNLL2003\" \\\n",
    "                    --model_type bert \\\n",
    "                    --model_name_or_path \"/content/drive/MyDrive/NLP/output/multilingual/MLM_cased/wikil_eng_wiki_ita\" \\\n",
    "                    --output_dir  \"/content/drive/MyDrive/NLP/output/multilingual/NER_cased/conll2003\" \\\n",
    "                    --num_train_epochs 3 \\\n",
    "                    --wandb_key $wandb_key \\\n",
    "                    --wandb_project CharBERT \\\n",
    "                    --learning_rate 3e-5 \\\n",
    "                    --char_vocab \"/content/CharBERT/data/dict/bert_char_vocab\" \\\n",
    "                    --per_gpu_train_batch_size 6 \\\n",
    "                    --do_train \\\n",
    "                    --do_predict \\\n",
    "                    --overwrite_output_dir \\\n",
    "                    --save_steps 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ner Multilingual CoNLL2003 Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./CharBERT/run_ner.py \\\n",
    "                    --data_dir \"/content/drive/MyDrive/NLP/data/CoNLL2003_ita\" \\\n",
    "                    --model_type bert \\\n",
    "                    --model_name_or_path \"/content/drive/MyDrive/NLP/output/multilingual//MLM_cased/wikil_eng_wiki_ita\" \\\n",
    "                    --output_dir  \"/content/drive/MyDrive/NLP/output/multilingual/NER_cased/conll2003_ita\" \\\n",
    "                    --num_train_epochs 3 \\\n",
    "                    --wandb_key $wandb_key \\\n",
    "                    --wandb_project CharBERT \\\n",
    "                    --learning_rate 3e-5 \\\n",
    "                    --char_vocab \"/content/CharBERT/data/dict/bert_char_vocab\" \\\n",
    "                    --per_gpu_train_batch_size 6 \\\n",
    "                    --do_train \\\n",
    "                    --do_predict \\\n",
    "                    --overwrite_output_dir \\\n",
    "                    --save_steps 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
